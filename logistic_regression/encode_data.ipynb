{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "208c6505",
   "metadata": {},
   "source": [
    "This notebook preprocess the aggregated data and the small granular sets, to preprare for training a logistic regression with granular data and  aggregated labels, following the method proposed by the challenge winners.\n",
    "Here we one-hot encode in a common space the modalities of each feature and the pairs of modalities of each pair of feature.\n",
    "Following the notations of the paper, we thus specify the function x -> K(x)\n",
    "We apply this encoding to:\n",
    "- both aggregated data (singles and pairs) files, to get the vector D, C, and S of aggregated displays counts, clicks and sales respectively. We thus get D := Sum_{large train set} K(x)\n",
    " ,  C := Sum_{large train set} K(x)*Click  and S := Sum_{large train set} K(x) * Sale\n",
    "- the 'small' test set and the 'large' test set: in each line x,y of those files, we compute the list of component of  K(x) which are equal to 1  \n",
    "- we save the resulting encoded data to disk.\n",
    "\n",
    "This encoding step is a bit slow (several hours). Note that the training after that is extremly fast (a few minutes to train a model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc62dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common libs to import everywhere\n",
    "import gc\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7554defc",
   "metadata": {},
   "source": [
    "# Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac0b9e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat '../data/aggregated_singles.csv' | head -2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f138862",
   "metadata": {},
   "outputs": [],
   "source": [
    "COL_singles_mod = 0\n",
    "COL_singles_clicks = 1\n",
    "COL_singles_sales = 2\n",
    "COL_singles_counts = 3\n",
    "COL_singles_fid = 4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdbf1a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xy_agg_data_singles = np.loadtxt(\"../data/aggregated_singles.csv\", skiprows=1, delimiter=\",\", dtype=np.int32)[:, 1:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c05796",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat '../data/aggregated_pairs.csv' | head -2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "978a1fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "COL_pairs_mod1 = 0\n",
    "COL_pairs_mod2 = 1\n",
    "COL_pairs_clicks = 2\n",
    "COL_pairs_sales = 3\n",
    "COL_pairs_counts = 4\n",
    "COL_pairs_fid1 = 5\n",
    "COL_pairs_fid2 = 6\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6377ab4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xy_agg_data_full = np.loadtxt(\"../data/aggregated_pairs.csv\", skiprows=1, delimiter=\",\", dtype=np.int32)[:, 1:]\n",
    "Xy_agg_data_full.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e1e024",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat '../data/X_test.csv' | head -2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f8b268",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Almost 1M granular unlabeled samples from the Test set\n",
    "\n",
    "X_test = np.loadtxt(\"../data/X_test.csv\", skiprows=1, delimiter=\",\", dtype=np.int32)\n",
    "X_test.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded03fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# More granular samples, from another set to compare perfs.\n",
    "\n",
    "X_another_set = np.loadtxt(\"../data/criteo-ppml-challenge-adkdd21-dataset-additional-test-data.csv\", skiprows=1, delimiter=\",\", dtype=np.int32)[:,:19]\n",
    "X_another_set.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d612c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Labels  (Used for computing validation score, not used for training!)\n",
    "\n",
    "Y_clicks_test = np.loadtxt(\"../data/y_test.csv\", skiprows=1, delimiter=\",\", dtype=np.int32, usecols=(0,))\n",
    "Y_sales_test = np.loadtxt(\"../data/y_test.csv\", skiprows=1, delimiter=\",\", dtype=np.int32, usecols=(1,))\n",
    "\n",
    "Y_clicks_another_set = np.loadtxt(\"../data/criteo-ppml-challenge-adkdd21-dataset-additional-test-data.csv\", skiprows=1, delimiter=\",\", dtype=np.int32, usecols=(19,))\n",
    "Y_sales_another_set = np.loadtxt(\"../data/criteo-ppml-challenge-adkdd21-dataset-additional-test-data.csv\", skiprows=1, delimiter=\",\", dtype=np.int32, usecols=(20,))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "009eed76",
   "metadata": {},
   "outputs": [],
   "source": [
    "## to run faster -> remove crosses with small volume\n",
    "# minDisplays = 1000\n",
    "# ind = np.where(Xy_agg_data[:,COL_pairs_counts] > minDisplays )[0]\n",
    "# print( \"Proportion kept crosses\"  ,  len(ind)/Xy_agg_data_full.shape[0] )\n",
    "\n",
    "# Xy_agg_data_full = Xy_agg_data_full[ind,:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cac7f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b06a18f",
   "metadata": {},
   "source": [
    "# One- hot encoding single features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d37343aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# features =sorted(set( Xy_agg_data_singles[:,COL_singles_fid] ))\n",
    "features = np.arange(0, 19)\n",
    "features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a7c1452",
   "metadata": {},
   "outputs": [],
   "source": [
    "## One-hot encoding all modalities\n",
    "#  Giving one distinct id, starting from 1, to each modality of each feature.\n",
    "#  (ie first feature modalities will get ids 1,2,...n; 2 feature will get n+1, n+2, ... )\n",
    "modalities_per_feature = {}\n",
    "offset = 1\n",
    "for f in features:\n",
    "    modalities = Xy_agg_data_singles[:, COL_singles_mod][Xy_agg_data_singles[:, COL_singles_fid] == f]\n",
    "    modalities = sorted(set(modalities))\n",
    "    dico = {m: i + offset for i, m in enumerate(modalities)}  ## +1:  keeping \"0\" for 'unknown' modality\n",
    "    modalities_per_feature[f] = dico\n",
    "    offset += len(dico)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7235d63f",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array([len(modalities_per_feature[f]) for f in modalities_per_feature])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae421bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_feature(modalities, dico):\n",
    "    return np.array([dico.get(m, 0) for m in modalities])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a9f953a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in features:\n",
    "    X_test[:, f] = encode_feature(X_test[:, f], modalities_per_feature[f])\n",
    "    X_another_set[:, f] = encode_feature(X_another_set[:, f], modalities_per_feature[f])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59dc34ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Replacing features by one-hot index in Xy_agg_data_singles\n",
    "\n",
    "x = np.array([modalities_per_feature[a[COL_singles_fid]].get(a[COL_singles_mod], 0) for a in Xy_agg_data_singles])\n",
    "Xy_agg_data_singles[:, COL_singles_mod] = x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af907f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Replacing features by one-hot index in Xy_agg_data\n",
    "\n",
    "Xy_agg_data_full[:, COL_pairs_mod1] = np.array(\n",
    "    [modalities_per_feature[a[COL_pairs_fid1]].get(a[COL_pairs_mod1], 0) for a in Xy_agg_data_full]\n",
    ")\n",
    "Xy_agg_data_full[:, COL_pairs_mod2] = np.array(\n",
    "    [modalities_per_feature[a[COL_pairs_fid2]].get(a[COL_pairs_mod2], 0) for a in Xy_agg_data_full]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ea7e2ef",
   "metadata": {},
   "source": [
    "# One-hot encoding all pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c363521d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = sorted(set([(a[COL_pairs_fid1], a[COL_pairs_fid2]) for a in Xy_agg_data_full]))\n",
    "len(pairs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "058a5342",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_cf(x, f, f2, dico):\n",
    "    return np.array([dico.get((a[f], a[f2]), 0) for a in x])\n",
    "\n",
    "\n",
    "def appended_encoded_cf(x, f, f2, dico):\n",
    "    col = encode_cf(x, f, f2, dico)\n",
    "    return np.c_[x, col]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00da6a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "COL_pairs_encodedpair = 0  ## reusing this colum\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01aa1cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "offset_pairs = offset\n",
    "\n",
    "for pair in pairs:\n",
    "    print(pair, \"     \", end=\"\\r\")\n",
    "    f = pair[0]\n",
    "    f2 = pair[1]\n",
    "    ind = np.where((Xy_agg_data_full[:, COL_pairs_fid1] == f) & (Xy_agg_data_full[:, COL_pairs_fid2] == f2))[0]\n",
    "    x = Xy_agg_data_full[ind, :]\n",
    "    modalities_pairs = sorted(set([(a[COL_pairs_mod1], a[COL_pairs_mod2]) for a in x]))\n",
    "    dico = {m: i + offset_pairs for i, m in enumerate(modalities_pairs)}\n",
    "    offset_pairs += len(dico)\n",
    "\n",
    "    # writting encoded pair in first column\n",
    "    Xy_agg_data_full[ind, COL_pairs_encodedpair] = np.array(\n",
    "        [dico.get((a[COL_pairs_mod1], a[COL_pairs_mod2]), 0) for a in x]\n",
    "    )\n",
    "\n",
    "    X_test = appended_encoded_cf(X_test, f, f2, dico)\n",
    "    X_another_set = appended_encoded_cf(X_another_set, f, f2, dico)\n",
    "\n",
    "    gc.collect()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2c7cf96",
   "metadata": {},
   "source": [
    "# Vectors of aggregated data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8acd8945",
   "metadata": {},
   "outputs": [],
   "source": [
    "D = np.zeros(offset_pairs)\n",
    "C = np.zeros(offset_pairs)\n",
    "S = np.zeros(offset_pairs)\n",
    "D[Xy_agg_data_full[:, COL_pairs_encodedpair]] += Xy_agg_data_full[:, COL_pairs_counts]\n",
    "D[Xy_agg_data_singles[:, COL_singles_mod]] += Xy_agg_data_singles[:, COL_singles_counts]\n",
    "\n",
    "\n",
    "S[Xy_agg_data_full[:, COL_pairs_encodedpair]] += Xy_agg_data_full[:, COL_pairs_sales]\n",
    "S[Xy_agg_data_singles[:, COL_singles_mod]] += Xy_agg_data_singles[:, COL_singles_sales]\n",
    "\n",
    "C[Xy_agg_data_full[:, COL_pairs_encodedpair]] += Xy_agg_data_full[:, COL_pairs_clicks]\n",
    "C[Xy_agg_data_singles[:, COL_singles_mod]] += Xy_agg_data_singles[:, COL_singles_clicks]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d1c90a0",
   "metadata": {},
   "source": [
    "# Save / Load\n",
    "- one-hot encoding is slow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae3e12c",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_samples_agg = Xy_agg_data_singles[Xy_agg_data_singles[:, COL_singles_fid] == 0][:, COL_singles_counts].sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "577b5c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = f\"../data/encodedAggData_C_D_S_X_Xbis_n_pairs\"\n",
    "np.savez(name, C=C, D=D, S=S, X_test=X_test, X_another_set=X_another_set, nb_samples_agg=nb_samples_agg, pairs=pairs)\n"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "interpreter": {
   "hash": "a36b085e9ff735ee0fad94699c928a54e5528d32a02652250964e3ed6cb11995"
  },
  "kernelspec": {
   "display_name": "aggregate_models_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
